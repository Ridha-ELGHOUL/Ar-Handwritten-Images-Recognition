{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c6TiNABwkAhe"
   },
   "source": [
    "# Arabic Handwritten Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yLgu44Fvkgdr"
   },
   "source": [
    "## Overview\n",
    "The automatic recognition of text on scanned images has enabled many applications such as searching for words in large volumes of documents, automatic sorting of postal mail, and convenient editing of previously printed documents.\n",
    "\n",
    "The domain of handwriting in the Arabic script presents unique technical challenges and has been addressed more recently than other domains. Many different methods have been proposed and applied to various types of images.\n",
    "\n",
    "Here we will focus on the recognition part of handwritten Arabic letters and digits recognition that face several challenges, including the unlimited variation in human handwriting and the large public databases.\n",
    "\n",
    "In this project we will employ several deep learning models to classify a the images to an arabic letter or digit. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDxpa4JAonJF"
   },
   "source": [
    "## Dataset\n",
    "The dataset for this project originates from kaggle kernels which include \n",
    "**[Arabic Digits](https://www.kaggle.com/mloey1/ahdd1)** and **[Arabic Letters](https://www.kaggle.com/mloey1/ahcd1)**.\n",
    "\n",
    "All the datasets are CSV files representing the image pixels values and their corresponding label.\n",
    "\n",
    "Here are some more details about the datasets:\n",
    "\n",
    "* **Arabic Digits Dataset represents MADBase** (modified Arabic handwritten digits database) which contains **60,000 training images, and 10,000 test images**. MADBase was **written by 700 writers**. Each writer wrote each digit (from 0 -9) ten times. To ensure including different writing styles, the database was gathered from different institutions: Colleges of Engineering and Law, School of Medicine, the Open University (whose students span a wide range of ages), a high school, and a governmental institution. MADBase is available for free and can be downloaded from [here](http://datacenter.aucegypt.edu/shazeem/).\n",
    "\n",
    "* **Arabic Letters Dataset is composed of 16,800 characters written by 60 participants**, the age range is between 19 to 40 years, and 90% of participants are right-hand. Each participant wrote each character (from ’alef’ to ’yeh’) ten times. The images were scanned at the resolution of 300 dpi. Each block is segmented automatically using Matlab 2016a to determining the coordinates for each block. **The dataset is partitioned into two sets: a training set of 13,440 characters to 480 images per class and a test set of 3,360 characters to 120 images per class**. Writers of training set and test set are exclusive. Ordering of including writers to test set are randomized to make sure that writers of test set are not from a single institution to ensure variability of the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m6_ru2oupR7h"
   },
   "source": [
    "## Data Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q2Z4_QkxppsF"
   },
   "source": [
    "1. We need to mount to google drive to be able to use the uploaded dataset files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4686,
     "status": "ok",
     "timestamp": 1537570398935,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "qNoWN1Ts6SFr",
    "outputId": "7725ab9b-c153-4db0-adcc-3b0d87ec944f"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jJo8eDIRp5ku"
   },
   "source": [
    "2. Import libraries necessary for this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3o6mEbK6W9v"
   },
   "outputs": [],
   "source": [
    "# Import main libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "# Import libraries needed for reading image and processing it\n",
    "import csv\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X0ubj6mrqXku"
   },
   "source": [
    "3. Load the dataset files into dataframes to be used later in the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rGcWZ2BBrLrr"
   },
   "source": [
    "### Loading Arabic Letters Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14920,
     "status": "ok",
     "timestamp": 1537570415152,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "1MRwVjsDKpCN",
    "outputId": "d1b4f3fb-01bd-45e3-97af-b5e62f940e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13440 training arabic letter images of 64x64 pixels.\n",
      "There are 3360 testing arabic letter images of 64x64 pixels.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  4086  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "   4087  4088  4089  4090  4091  4092  4093  4094  4095  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 4096 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training letters images and labels files\n",
    "letters_training_images_file_path = \"Arabic Handwritten Characters Dataset CSV/training images.zip\"\n",
    "letters_training_labels_file_path = \"Arabic Handwritten Characters Dataset CSV/training labels.zip\"\n",
    "# Testing letters images and labels files\n",
    "letters_testing_images_file_path = \"Arabic Handwritten Characters Dataset CSV/testing images.zip\"\n",
    "letters_testing_labels_file_path = \"Arabic Handwritten Characters Dataset CSV/testing labels.zip\"\n",
    "\n",
    "# Loading dataset into dataframes\n",
    "training_letters_images = pd.read_csv(letters_training_images_file_path, compression='zip', header=None)\n",
    "training_letters_labels = pd.read_csv(letters_training_labels_file_path, compression='zip', header=None)\n",
    "testing_letters_images = pd.read_csv(letters_testing_images_file_path, compression='zip', header=None)\n",
    "testing_letters_labels = pd.read_csv(letters_testing_labels_file_path, compression='zip', header=None)\n",
    "\n",
    "# print statistics about the dataset\n",
    "print(\"There are %d training arabic letter images of 64x64 pixels.\" %training_letters_images.shape[0])\n",
    "print(\"There are %d testing arabic letter images of 64x64 pixels.\" %testing_letters_images.shape[0])\n",
    "training_letters_images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KuPNRawns2BV"
   },
   "source": [
    "### Loading Arabic Digits Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55279,
     "status": "ok",
     "timestamp": 1537570470503,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "Zyoid-WpLjXT",
    "outputId": "3c91821c-d2c2-4ae1-fe3c-66481f4f0bfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60000 training arabic digit images of 64x64 pixels.\n",
      "There are 10000 testing arabic digit images of 64x64 pixels.\n"
     ]
    }
   ],
   "source": [
    "# Training digits images and labels files\n",
    "digits_training_images_file_path = \"Arabic Handwritten Digits Dataset CSV/training images.zip\"\n",
    "digits_training_labels_file_path = \"Arabic Handwritten Digits Dataset CSV/training labels.zip\"\n",
    "# Testing digits images and labels files\n",
    "digits_testing_images_file_path = \"Arabic Handwritten Digits Dataset CSV/testing images.zip\"\n",
    "digits_testing_labels_file_path = \"Arabic Handwritten Digits Dataset CSV/testing labels.zip\"\n",
    "\n",
    "# Loading dataset into dataframes\n",
    "training_digits_images = pd.read_csv(digits_training_images_file_path, compression='zip', header=None)\n",
    "training_digits_labels = pd.read_csv(digits_training_labels_file_path, compression='zip', header=None)\n",
    "testing_digits_images = pd.read_csv(digits_testing_images_file_path, compression='zip', header=None)\n",
    "testing_digits_labels = pd.read_csv(digits_testing_labels_file_path, compression='zip', header=None)\n",
    "\n",
    "# print statistics about the dataset\n",
    "print(\"There are %d training arabic digit images of 64x64 pixels.\" %training_digits_images.shape[0])\n",
    "print(\"There are %d testing arabic digit images of 64x64 pixels.\" %testing_digits_images.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LGFth_ks0VH4"
   },
   "source": [
    "### Convert csv values to an image \n",
    "Writting a method to be used later if we want visualization of an image from its pixels values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2MbTUT_mMBGH"
   },
   "outputs": [],
   "source": [
    "def convert_values_to_image(image_values, display=False):\n",
    "  image_array = np.asarray(image_values)\n",
    "  image_array = image_array.reshape(64, 64).astype('uint8')\n",
    "  # The original dataset is reflected so we will flip it then rotate for a better view only.\n",
    "  image_array = np.flip(image_array, 0)\n",
    "  image_array = rotate(image_array, -90)\n",
    "  new_image = Image.fromarray(image_array)\n",
    "  if display == True:\n",
    "    new_image.show()\n",
    "  return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MBwu1eDk0mjj"
   },
   "source": [
    "### Visualizing some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2028,
     "status": "ok",
     "timestamp": 1537570474704,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "pX4PxwqbyQg8",
    "outputId": "956132bf-ceaf-45d8-ad1c-0748677e12a6"
   },
   "outputs": [],
   "source": [
    "convert_values_to_image(training_letters_images.loc[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1478,
     "status": "ok",
     "timestamp": 1537570476246,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "R0J_oTy0yeXb",
    "outputId": "6b7ff313-0a01-402d-945e-a8f8085dfb45"
   },
   "outputs": [],
   "source": [
    "convert_values_to_image(training_letters_images.loc[12], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2027,
     "status": "ok",
     "timestamp": 1537570478338,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "IVwNBEIj2dcK",
    "outputId": "8bde3cea-15e4-45e4-8ff5-c2299e1a1849"
   },
   "outputs": [],
   "source": [
    "convert_values_to_image(training_letters_images.loc[37], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1351,
     "status": "ok",
     "timestamp": 1537570479775,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "pNKxXW5-2fl9",
    "outputId": "1118ceb2-022f-4f23-88de-8bcfb43d56c7"
   },
   "outputs": [],
   "source": [
    "convert_values_to_image(training_letters_images.loc[3000], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2119,
     "status": "ok",
     "timestamp": 1537570481961,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "FIYtePhT2iBr",
    "outputId": "7ef75d68-74fd-41af-82dc-93774e1f4424"
   },
   "outputs": [],
   "source": [
    "convert_values_to_image(training_digits_images.loc[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2273,
     "status": "ok",
     "timestamp": 1537570484302,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "zdnSlqNxYB_H",
    "outputId": "ec27d7df-ff90-4d3d-ec8e-cc10afd3f0fa"
   },
   "outputs": [],
   "source": [
    "convert_values_to_image(training_digits_images.loc[2], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1515,
     "status": "ok",
     "timestamp": 1537570485885,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "hlSt-2_2i8O1",
    "outputId": "22dc1bb1-6c99-45cb-fe6b-151e594ff922"
   },
   "outputs": [],
   "source": [
    "convert_values_to_image(training_digits_images.loc[7], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1414,
     "status": "ok",
     "timestamp": 1537570487368,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "xsucycIri9ht",
    "outputId": "04ec1a5e-6afa-472b-ae44-1dcb433b54a2"
   },
   "outputs": [],
   "source": [
    "convert_values_to_image(training_digits_images.loc[9], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZT4fEuLoLXw"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TZH8hpO_qgem"
   },
   "source": [
    "### Image Normalization\n",
    "We rescale the images by dividing every pixel in the image by 255 to make them into range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1HJI0WG0oNmT"
   },
   "outputs": [],
   "source": [
    "training_digits_images_scaled = training_digits_images.values.astype('float32')/255\n",
    "training_digits_labels = training_digits_labels.values.astype('int32')\n",
    "testing_digits_images_scaled = testing_digits_images.values.astype('float32')/255\n",
    "testing_digits_labels = testing_digits_labels.values.astype('int32')\n",
    "\n",
    "training_letters_images_scaled = training_letters_images.values.astype('float32')/255\n",
    "training_letters_labels = training_letters_labels.values.astype('int32')\n",
    "testing_letters_images_scaled = testing_letters_images.values.astype('float32')/255\n",
    "testing_letters_labels = testing_letters_labels.values.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1370,
     "status": "ok",
     "timestamp": 1537570491510,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "4GtF5Gc4sGsv",
    "outputId": "92b96de8-2684-4d9d-8f49-26f238f81dd8"
   },
   "outputs": [],
   "source": [
    "print(\"Training images of digits after scaling\")\n",
    "print(training_digits_images_scaled.shape)\n",
    "training_digits_images_scaled[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1097,
     "status": "ok",
     "timestamp": 1537570492675,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "n68sxKC0sTkq",
    "outputId": "2e1e664b-c37b-445b-83d8-f6e4f34ca8a3"
   },
   "outputs": [],
   "source": [
    "print(\"Training images of letters after scaling\")\n",
    "print(training_letters_images_scaled.shape)\n",
    "training_letters_images_scaled[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-X1SJjnsq8b"
   },
   "source": [
    "### Encoding Categorical Labels\n",
    "From the labels csv files we can see that labels are categorical values and it is a multi-class classification problem. \n",
    "\n",
    "Our outputs are in the form of:\n",
    "* Digits from 0 to 9 have categories numbers from 0 to 9\n",
    "* Letters from ’alef’ to ’yeh’ have categories numbers from 10 to 37\n",
    "\n",
    "**Here we will encode these categories values using One Hot Encoding with keras.**\n",
    "\n",
    "One-hot encoding transforms integer to a binary matrix where the array contains only one ‘1’ and the rest elements are ‘0’.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQyT17YzsU7U"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# one hot encoding\n",
    "# number of classes = 10 (digits classes) + 28 (arabic alphabet classes)\n",
    "number_of_classes = 38\n",
    "training_letters_labels_encoded = to_categorical(training_letters_labels, num_classes=number_of_classes)\n",
    "testing_letters_labels_encoded = to_categorical(testing_letters_labels, num_classes=number_of_classes)\n",
    "training_digits_labels_encoded = to_categorical(training_digits_labels, num_classes=number_of_classes)\n",
    "testing_digits_labels_encoded = to_categorical(testing_digits_labels, num_classes=number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1490,
     "status": "ok",
     "timestamp": 1537570495783,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "9CyoYTDl1BXD",
    "outputId": "8c231477-6cff-44d0-a65c-ccd05c25e79c"
   },
   "outputs": [],
   "source": [
    "print(training_digits_labels_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nsJzI6Gp5bbA"
   },
   "source": [
    "### Reshaping Input Images to 64x64x1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VDldXMz76EQH"
   },
   "source": [
    "When using TensorFlow as backend, Keras CNNs require a 4D array (which we'll also refer to as a 4D tensor) as input, with shape\n",
    "(nb_samples,rows,columns,channels)\n",
    "\n",
    "where nb_samples corresponds to the total number of images (or samples), and rows, columns, and channels correspond to the number of rows, columns, and channels for each image, respectively.\n",
    "\n",
    "**So we will reshape the input images to a 4D tensor with shape\n",
    "(nb_samples, 64, 64 ,1)** as we use grayscale images of 64x64 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1398,
     "status": "ok",
     "timestamp": 1537570497246,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "EWTQ0nq85wWL",
    "outputId": "701f6ed5-72e3-4542-b87f-70d6e953c21a"
   },
   "outputs": [],
   "source": [
    "# reshape input digit images to 64x64x1\n",
    "training_digits_images_scaled = training_digits_images_scaled.reshape([-1, 64, 64, 1])\n",
    "testing_digits_images_scaled = testing_digits_images_scaled.reshape([-1, 64, 64, 1])\n",
    "\n",
    "# reshape input letter images to 64x64x1\n",
    "training_letters_images_scaled = training_letters_images_scaled.reshape([-1, 64, 64, 1])\n",
    "testing_letters_images_scaled = testing_letters_images_scaled.reshape([-1, 64, 64, 1])\n",
    "\n",
    "print(training_digits_images_scaled.shape, training_digits_labels_encoded.shape, testing_digits_images_scaled.shape, testing_digits_labels_encoded.shape)\n",
    "print(training_letters_images_scaled.shape, training_letters_labels_encoded.shape, testing_letters_images_scaled.shape, testing_letters_labels_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gtsr1vVaYS9D"
   },
   "source": [
    "### Merging Letters and Digits Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2701,
     "status": "ok",
     "timestamp": 1537570500022,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "1bdfCcFpYpA_",
    "outputId": "7444f2af-f98c-43e9-c200-814357cd7461"
   },
   "outputs": [],
   "source": [
    "training_data_images = np.concatenate((training_digits_images_scaled, training_letters_images_scaled), axis=0) \n",
    "training_data_labels = np.concatenate((training_digits_labels_encoded, training_letters_labels_encoded), axis=0)\n",
    "print(\"Total Training images are {} images of shape\".format(training_data_images.shape[0]))\n",
    "print(training_data_images.shape, training_data_labels.shape)\n",
    "\n",
    "\n",
    "testing_data_images = np.concatenate((testing_digits_images_scaled, testing_letters_images_scaled), axis=0) \n",
    "testing_data_labels = np.concatenate((testing_digits_labels_encoded, testing_letters_labels_encoded), axis=0)\n",
    "print(\"Total Testing images are {} images of shape\".format(testing_data_images.shape[0]))\n",
    "print(testing_data_images.shape, testing_data_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bsZR7mb89UoI"
   },
   "source": [
    "## Designing Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7DImv-hIKSOf"
   },
   "source": [
    "Now we will make a method which creates the model architecture with the specified optimizer and activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHOTAM-w79Ak"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Dropout, Dense\n",
    "\n",
    "def create_model(optimizer='adam', kernel_initializer='he_normal', activation='relu'):\n",
    "  # create model\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(filters=16, kernel_size=3, padding='same', input_shape=(64, 64, 1), kernel_initializer=kernel_initializer, activation=activation))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=2))\n",
    "  model.add(Dropout(0.2))\n",
    "\n",
    "  model.add(Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer=kernel_initializer, activation=activation))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=2))\n",
    "  model.add(Dropout(0.2))\n",
    "\n",
    "  model.add(Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer=kernel_initializer, activation=activation))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=2))\n",
    "  model.add(Dropout(0.2))\n",
    "\n",
    "  model.add(Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer=kernel_initializer, activation=activation))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=2))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(GlobalAveragePooling2D())\n",
    "  \n",
    "  #Fully connected final layer\n",
    "  model.add(Dense(38, activation='softmax'))\n",
    "\n",
    "  # Compile model\n",
    "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wuqb1snmHPqW"
   },
   "source": [
    "Let’s understand above code step by step.\n",
    "\n",
    "* The first hidden layer is a convolutional layer. The layer has 16 feature maps, which with the size of 3×3 and an activation function which is relu. This is the input layer, expecting images with the structure outlined above.\n",
    "* The second layer is Batch Normalization which solves having distributions of the features vary across the training and test data, which breaks the IID assumption. We use it to help in two ways faster learning and higher overall accuracy. \n",
    "* The third layer is the MaxPooling layer. MaxPooling layer is used to down-sample the input to enable the model to make assumptions about the features so as to reduce overfitting. It also reduces the number of parameters to learn, reducing the training time.\n",
    "* The next layer is a Regularization layer using dropout. It is configured to randomly exclude 20% of neurons in the layer in order to reduce overfitting.\n",
    "* Another hidden layer with 32 feature maps with the size of 3×3 and a relu activation function to capture more features from the image.\n",
    "* Other hidden layers with 64 and 128 feature maps with the size of 3×3 and a relu activation function to capture complex patterns from the image which will decribe the digits and letters later.\n",
    "* More MaxPooling, Batch Normalization, Regularization and GlobalAveragePooling2D layers.\n",
    "* The last layer is the output layer with 10 neurons (number of output classes) and it uses softmax activation function as we have multi-classes. Each neuron will give the probability of that class.\n",
    "\n",
    "I used categorical_crossentropy as a loss function because its a multi-class classification problem. I used accuracy as metrics to improve the performance of our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_GdoRPe6LiRV"
   },
   "source": [
    "## Model Summary And Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RLAADtoKMkcB"
   },
   "source": [
    "Let's see the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2480,
     "status": "ok",
     "timestamp": 1537570504179,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "GzgiwjyPLmrp",
    "outputId": "a0994d53-e0fa-44e1-b059-89175b84b242"
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F-WXi7zkLxuN"
   },
   "source": [
    "Keras support plotting the model in keras.utils.vis_utils module which provides utility functions to plot a Keras model using graphviz.\n",
    "\n",
    "To be able to use that utility we should first install pydot and graphviz modules. This can be done by running the following code cell then restart the runtime environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1989
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14864,
     "status": "ok",
     "timestamp": 1537570062715,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "uIL81Yib39V6",
    "outputId": "49afb7a2-3b46-48b0-d7e6-7a99ed6d723b"
   },
   "outputs": [],
   "source": [
    "# https://pypi.python.org/pypi/pydot\n",
    "!apt-get -qq install -y graphviz && pip install -q pydot\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eyEMpJx3MttP"
   },
   "source": [
    "Now we can plot the model and save it to a file also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2082
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3556,
     "status": "ok",
     "timestamp": 1537570507791,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "B1zpgDtwMtEU",
    "outputId": "c8985530-4076-4511-e982-64e194a1af74"
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file=\"model.png\", show_shapes=True)\n",
    "from IPython.display import Image as IPythonImage\n",
    "display(IPythonImage('model.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XKburGrWjUug"
   },
   "source": [
    "## Parameters Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oz6ZOYT5jde-"
   },
   "source": [
    "We will tune the parameters optimizer, kernel_initializer and activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1853,
     "status": "ok",
     "timestamp": 1537570509726,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "iqd8pUpo1vC3",
    "outputId": "e8b9bd6f-c30f-4325-e368-877abff2e31f"
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# define the grid search parameters\n",
    "optimizer = ['RMSprop', 'Adam', 'Adagrad', 'Nadam']\n",
    "kernel_initializer = ['normal', 'uniform']\n",
    "activation = ['relu', 'linear', 'tanh']\n",
    "\n",
    "param_grid = dict(optimizer=optimizer, kernel_initializer=kernel_initializer, activation=activation)\n",
    "\n",
    "# count number of different parameters values combinations\n",
    "parameters_number = 1\n",
    "for x in param_grid:\n",
    "  parameters_number = parameters_number * len(param_grid[x]) \n",
    "print(\"Number of different parameter combinations = {}\".format(parameters_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rn5e1UWniPmD"
   },
   "source": [
    "We will try different models with different parameters to find the best parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5341
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10697207,
     "status": "ok",
     "timestamp": 1537581207010,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "kbtGq865gbEW",
    "outputId": "628f25ba-bd1f-4101-f64b-00f07395a0e4"
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 20 # 20 divides the training data samples\n",
    "\n",
    "#creating the models with different hyperparameters\n",
    "for a,b,c in [(x,y,z) for x in optimizer for z in activation for y in kernel_initializer]:\n",
    "    params = {'optimizer' : a , 'kernel_initializer' : b , 'activation' : c}\n",
    "    print(params)\n",
    "    curr_model = create_model(a, b, c)\n",
    "    curr_model.fit(training_data_images, training_data_labels, \n",
    "                    validation_data=(testing_data_images, testing_data_labels),\n",
    "                    epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "    print(\"=============================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TgVoF_U9ifx0"
   },
   "source": [
    "**From the above results we can see that best parameters are:**\n",
    "* **Optimizer: Adam**\n",
    "* **Kernel_initializer: uniform**\n",
    "* **Activation: relu** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nt9JJvWzjKpf"
   },
   "source": [
    "Let's create the model with the best parameters obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQ61tTgthNX3"
   },
   "outputs": [],
   "source": [
    "model = create_model(optimizer='Adam', kernel_initializer='uniform', activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SAyJLJOsJdKY"
   },
   "source": [
    "## Training the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9REBW24cmdKI"
   },
   "source": [
    "### Fitting the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i8GiTDtRkZTp"
   },
   "source": [
    "Train the model using batch_size=20 to reduce used memory and make the training more quick.\n",
    "We will train the model first on 10 epochs to see the accuracy that we will obtain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 904503,
     "status": "ok",
     "timestamp": 1537582891920,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "fOtKJTQ51qC5",
    "outputId": "7cad5b4b-6c0d-467a-d3e8-b39cf0fb08a9"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "# using checkpoints to save model weights to be used later instead of training again on the same epochs.\n",
    "checkpointer = ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True)\n",
    "history = model.fit(training_data_images, training_data_labels, \n",
    "                    validation_data=(testing_data_images, testing_data_labels),\n",
    "                    epochs=10, batch_size=20, verbose=1, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "etE1oULFCnSn"
   },
   "source": [
    "### Plotting Loss and Accuracy Curves with Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWyxaeKxCn9O"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_accuracy(history):\n",
    "  # Loss Curves\n",
    "  plt.figure(figsize=[8,6])\n",
    "  plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "  plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "  plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "  plt.xlabel('Epochs ',fontsize=16)\n",
    "  plt.ylabel('Loss',fontsize=16)\n",
    "  plt.title('Loss Curves',fontsize=16)\n",
    "\n",
    "  # Accuracy Curves\n",
    "  plt.figure(figsize=[8,6])\n",
    "  plt.plot(history.history['acc'],'r',linewidth=3.0)\n",
    "  plt.plot(history.history['val_acc'],'b',linewidth=3.0)\n",
    "  plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "  plt.xlabel('Epochs ',fontsize=16)\n",
    "  plt.ylabel('Accuracy',fontsize=16)\n",
    "  plt.title('Accuracy Curves',fontsize=16) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 805
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2140,
     "status": "ok",
     "timestamp": 1537583155675,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "LE9WKyG7GNSs",
    "outputId": "d610c15c-18ac-428c-9193-40a87bccce15"
   },
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p8QOKiQpmWDC"
   },
   "source": [
    "### Load the Model with the Best Validation Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OUunssvzmQUb"
   },
   "outputs": [],
   "source": [
    "model.load_weights('weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aijsry3Xmmv-"
   },
   "source": [
    "## Test the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5181,
     "status": "ok",
     "timestamp": 1537583170679,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "8h7E8G7CsCFB",
    "outputId": "ce7d4c98-e32c-4d49-8c4d-4a7bef7f3c30"
   },
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "metrics = model.evaluate(testing_data_images, testing_data_labels, verbose=1)\n",
    "print(\"Test Accuracy: {}\".format(metrics[1]))\n",
    "print(\"Test Loss: {}\".format(metrics[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xz04uhKPnFft"
   },
   "source": [
    "**We get test accuracy of 98.286% after training on 10 epochs only.**\n",
    "\n",
    "**What about increasing the epochs we train on ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rit6CswqnrEC"
   },
   "source": [
    "## Training More on the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1780630,
     "status": "ok",
     "timestamp": 1537585006745,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "BZAP7VW1npA-",
    "outputId": "0fc06279-2faa-4d2b-f358-edda4c304338"
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 20\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(training_data_images, training_data_labels, \n",
    "                    validation_data=(testing_data_images, testing_data_labels),\n",
    "                    epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[checkpointer])\n",
    "          \n",
    "model.load_weights('weights.hdf5')\n",
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 805
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2490,
     "status": "ok",
     "timestamp": 1537585110875,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "c8GWs-8bNsxR",
    "outputId": "acef3123-a33c-49bc-f759-5ce10a9d50a7"
   },
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RC6yRcCHoMa7"
   },
   "source": [
    "## Testing the Model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6816,
     "status": "ok",
     "timestamp": 1537585029877,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "Bm5y2MgXoP3F",
    "outputId": "4c262179-d450-4c3e-e621-a86814f8caa7"
   },
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "metrics = model.evaluate(testing_data_images, testing_data_labels, verbose=1)\n",
    "print(\"Test Accuracy: {}\".format(metrics[1]))\n",
    "print(\"Test Loss: {}\".format(metrics[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cVhqFs8oYwz"
   },
   "source": [
    "After training the model on more epochs we gained a better model which can classify complex patterns . So when we tested it on our test dataset we had better results than before.\n",
    "\n",
    "**Test accuracy is improved from 98.286% to 98.862% As we train the model on 20 more epochs.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUes2bqFqycc"
   },
   "source": [
    "## Saving the Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dA6vbYZKp0bB"
   },
   "source": [
    "Let's save the model on json format to be used later instead of creating the model again from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EVsTrDhop_XA"
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_yaml\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ozgwPPrArhoY"
   },
   "source": [
    "Save the model weights to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1040,
     "status": "ok",
     "timestamp": 1537585275078,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "jAVASfDAo_lN",
    "outputId": "efc9bb9b-444a-4191-a15f-9fed644fef7f"
   },
   "outputs": [],
   "source": [
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xv1bAB-ur15m"
   },
   "source": [
    "if we want to load the model with the last obtained weights at anytime, we will run the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5824,
     "status": "ok",
     "timestamp": 1537585282320,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "xD9ogMjqsCvJ",
    "outputId": "f20276ec-e599-480a-b2b4-fe5c8e5b318a"
   },
   "outputs": [],
   "source": [
    "# load YAML and create model\n",
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# compile the loaded model\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bvOiQNT-u6DQ"
   },
   "source": [
    "## Benchmark Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VljY9PAbwWfo"
   },
   "source": [
    "We will use a very simple (vanilla) CNN model as benchmark and Train/test it using the same data that you have used for our model solution.\n",
    "Then Compare the results between the vanilla model and our complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 211911,
     "status": "ok",
     "timestamp": 1537586300764,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "r3uAvHHzwW8D",
    "outputId": "e70b620d-73ef-4b69-dfb1-9719dc8ff6a0"
   },
   "outputs": [],
   "source": [
    "baseline_model = Sequential()\n",
    "baseline_model.add(Conv2D(filters=16, kernel_size=3, padding='same', input_shape=(64, 64, 1), activation='relu')) # Input layer\n",
    "baseline_model.add(GlobalAveragePooling2D())\n",
    "baseline_model.add(Dense(38, activation = 'softmax')) # Output layer => output dimension = 38 as it is multi-class\n",
    "\n",
    "# Compile the baseline model\n",
    "baseline_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='Adam')\n",
    "\n",
    "# Fit the baseline model with training dataset\n",
    "epochs = 5\n",
    "batch_size = 20\n",
    "\n",
    "baseline_model.fit(training_data_images, training_data_labels, \n",
    "                  validation_data=(testing_data_images, testing_data_labels),\n",
    "                  epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "# Test the baseline model\n",
    "baseline_metrics = baseline_model.evaluate(testing_data_images, testing_data_labels, verbose=1)\n",
    "print(\"Baseline Model Test Accuracy: {}\".format(baseline_metrics[1]))\n",
    "print(\"Baseline Model Test Loss: {}\".format(baseline_metrics[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2vaf6pNSiBj"
   },
   "source": [
    "**We get test accuracy of 32.37% from the baseline Model (vanilla). **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VKGKogPCMhZM"
   },
   "source": [
    "## Predict Image Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_TEpbiLtEtaW"
   },
   "source": [
    "Making a method which takes a model, data and its true labels (optional for using in testing). Then it gives the predicted classes of the given data using the given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXQEPxpGBJao"
   },
   "outputs": [],
   "source": [
    "def get_predicted_classes(model, data, labels=None):\n",
    "  image_predictions = model.predict(data)\n",
    "  predicted_classes = np.argmax(image_predictions, axis=1)\n",
    "  true_classes = np.argmax(labels, axis=1)\n",
    "  return predicted_classes, true_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mA_tBIt3A3xr"
   },
   "source": [
    "## Comparing Evaluation Metrics between Benchmark Model and Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LSPG55usTdyZ"
   },
   "source": [
    "Making a method which will print all metrics (precision, recall, f1-score and support) with each class in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rS1nOxCQSImh"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def get_classification_report(y_true, y_pred):\n",
    "  print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FdzM8mCUT0m1"
   },
   "source": [
    "### Evaluating Final Model using the specified metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5094,
     "status": "ok",
     "timestamp": 1537586583141,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "HgR-5MsXS0O3",
    "outputId": "e541a93e-5b3d-4f9d-cd30-860a24b6b6b8"
   },
   "outputs": [],
   "source": [
    "y_pred, y_true = get_predicted_classes(model, testing_data_images, testing_data_labels)\n",
    "get_classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MlYyVo8uUJqf"
   },
   "source": [
    "### Evaluating Baseline (Benchmark) Model using the specified metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2676,
     "status": "ok",
     "timestamp": 1537586828578,
     "user": {
      "displayName": "Amr Hendy",
      "photoUrl": "//lh4.googleusercontent.com/-dRbE1ZGijO8/AAAAAAAAAAI/AAAAAAAAANg/YkTGbPMb_FQ/s50-c-k-no/photo.jpg",
      "userId": "116082760662520987778"
     },
     "user_tz": -120
    },
    "id": "AbG3WPovTFQD",
    "outputId": "ed6edb73-41ae-4766-ece2-3143af66f389"
   },
   "outputs": [],
   "source": [
    "y_pred, y_true = get_predicted_classes(baseline_model, testing_data_images, testing_data_labels)\n",
    "get_classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FMrOKy46Ua1d"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T1UPKIl9Uew7"
   },
   "source": [
    "**We built a CNN model which can classify the arabic handwritten images into digits and letters. We tested the model on more than 13000 image with all possible classes and got very high accuracy of 98.86%.**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Arabic Handwritten Recognition.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
